"""
Kafka Consumer ëª¨ë“ˆ

sensor-raw-data í† í”½ì—ì„œ ì„¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ê³ 
ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""
from kafka import KafkaConsumer
from kafka.errors import KafkaError
import json
import logging
from typing import Optional
import signal

from ..config import settings
from ..ml.predictor import get_predictor
from ..cache.machine_cache import get_machine_cache
from ..db.repositories import get_outbox_repository
from ..db.models import Outbox
from .producer import get_alert_producer

logger = logging.getLogger(__name__)


class SensorDataConsumer:
    """
    ì„¼ì„œ ë°ì´í„° Consumer

    sensor-raw-data í† í”½ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ì—¬
    ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ Outboxì— ì €ì¥í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        """Kafka Consumer ë° ì˜ì¡´ì„± ì´ˆê¸°í™”"""
        try:
            # Kafka Consumer ìƒì„±
            self.consumer = KafkaConsumer(
                settings.KAFKA_TOPIC_SENSOR,
                bootstrap_servers=settings.kafka_servers_list,
                group_id=settings.KAFKA_GROUP_ID,
                value_deserializer=lambda m: json.loads(m.decode('utf-8')),
                key_deserializer=lambda k: k.decode('utf-8') if k else None,
                auto_offset_reset='latest',  # ìµœì‹  ë©”ì‹œì§€ë¶€í„° ì†Œë¹„
                enable_auto_commit=True,  # ìë™ ì˜¤í”„ì…‹ ì»¤ë°‹
                auto_commit_interval_ms=5000,  # 5ì´ˆë§ˆë‹¤ ì»¤ë°‹
                max_poll_records=100,  # í•œ ë²ˆì— ìµœëŒ€ 100ê°œ ë©”ì‹œì§€
                session_timeout_ms=30000,  # 30ì´ˆ
                heartbeat_interval_ms=10000  # 10ì´ˆ
            )

            # ì˜ì¡´ì„± ì£¼ì… (ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë“¤)
            self.predictor = get_predictor()
            self.cache = get_machine_cache()  # ìºì‹œ ë¯¸ìŠ¤ ì‹œ ìë™ DB ì¡°íšŒ
            self.repository = get_outbox_repository()
            self.alert_producer = get_alert_producer()

            # ì‹¤í–‰ í”Œë˜ê·¸
            self.running = False

            logger.info(
                f"SensorDataConsumer ì´ˆê¸°í™” ì™„ë£Œ: "
                f"topic={settings.KAFKA_TOPIC_SENSOR}, "
                f"group={settings.KAFKA_GROUP_ID}"
            )

        except Exception as e:
            logger.error(f"Kafka Consumer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def start(self) -> None:
        """
        Consumer ì‹œì‘ ë° ë©”ì‹œì§€ ì²˜ë¦¬ ë£¨í”„

        SIGINT (Ctrl+C)ë¡œ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
        # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

        self.running = True
        logger.info("SensorDataConsumer ì‹œì‘...")

        try:
            # ë©”ì‹œì§€ í´ë§ ë£¨í”„
            for message in self.consumer:
                if not self.running:
                    break

                try:
                    self._process_message(message)
                except Exception as e:
                    logger.error(
                        f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}, "
                        f"offset={message.offset}"
                    )
                    # ê°œë³„ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨ëŠ” ë¡œê¹…ë§Œ í•˜ê³  ê³„ì† ì§„í–‰

        except KafkaError as e:
            logger.error(f"Kafka ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            self.stop()

    def _process_message(self, message) -> None:
        """
        ê°œë³„ ë©”ì‹œì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

        Args:
            message: Kafka ë©”ì‹œì§€
        """
        # 1ë‹¨ê³„: ë©”ì‹œì§€ íŒŒì‹±
        sensor_data = message.value
        machine_id = sensor_data.get('machineId')

        if machine_id is None:
            logger.warning("machineIdê°€ ì—†ëŠ” ë©”ì‹œì§€ ìˆ˜ì‹ ")
            return

        logger.debug(
            f"ì„¼ì„œ ë°ì´í„° ìˆ˜ì‹ : machine_id={machine_id}, "
            f"partition={message.partition}, "
            f"offset={message.offset}"
        )

        # 2ë‹¨ê³„: ë¨¸ì‹  íƒ€ì… ì¡°íšŒ
        # cache.get_machine_type()ëŠ” ìºì‹œ ë¯¸ìŠ¤ ì‹œ ìë™ìœ¼ë¡œ Portal DB ì¡°íšŒ
        machine_type = self.cache.get_machine_type(machine_id)

        if machine_type is None:
            logger.warning(
                f"ë¨¸ì‹  íƒ€ì…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: machine_id={machine_id}. "
                f"Portal DBì— í•´ë‹¹ ë¨¸ì‹ ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )
            return

        # 3ë‹¨ê³„: ì´ìƒ íƒì§€ ì˜ˆì¸¡
        try:
            prediction_result = self.predictor.predict(
                sensor_data=sensor_data,
                machine_type=machine_type,
                return_probabilities=True
            )

            # 4ë‹¨ê³„: ì´ìƒ ê°ì§€ ì‹œ ì²˜ë¦¬
            if prediction_result['is_anomaly']:
                self._handle_anomaly(machine_id, sensor_data, prediction_result)
            else:
                logger.debug(
                    f"ì •ìƒ ë°ì´í„°: machine_id={machine_id}, "
                    f"normal_prob={prediction_result.get('normal_probability', 0):.4f}"
                )

        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ì²˜ë¦¬ ì‹¤íŒ¨ (machine_id={machine_id}): {e}")

    def _handle_anomaly(
        self,
        machine_id: int,
        sensor_data: dict,
        prediction_result: dict
    ) -> None:
        """
        ì´ìƒ íƒì§€ ì‹œ ì²˜ë¦¬ ë¡œì§

        1. Outboxì— ì´ë²¤íŠ¸ ì €ì¥ â†’ Debezium CDCê°€ ê°ì§€ â†’ Kafka ë°œí–‰
        2. (ì„ íƒì ) ì§ì ‘ Kafkaë¡œë„ ì•Œë¦¼ ë°œí–‰ ê°€ëŠ¥

        Args:
            machine_id: ë¨¸ì‹  ID
            sensor_data: ì„¼ì„œ ë°ì´í„°
            prediction_result: ì˜ˆì¸¡ ê²°ê³¼
        """
        logger.warning(
            f"ğŸš¨ ì´ìƒ íƒì§€! machine_id={machine_id}, "
            f"anomaly_prob={prediction_result.get('anomaly_probability', 0):.4f}"
        )

        try:
            # Outbox ì´ë²¤íŠ¸ ìƒì„±
            outbox_event = Outbox.create_anomaly_event(
                machine_id=machine_id,
                sensor_data=sensor_data,
                prediction_result=prediction_result
            )

            # DBì— ì €ì¥ (Debezium CDCê°€ ì´ë¥¼ ê°ì§€í•˜ì—¬ Kafkaë¡œ ë°œí–‰)
            saved_event = self.repository.save_event(outbox_event)

            logger.info(
                f"Outbox ì´ë²¤íŠ¸ ì €ì¥ ì™„ë£Œ: "
                f"id={saved_event.id}, "
                f"aggregate_id={saved_event.aggregate_id}"
            )

            # (ì„ íƒì ) ì¦‰ì‹œ Kafkaë¡œë„ ë°œí–‰
            # Debeziumê³¼ ë³„ê°œë¡œ ì‹¤ì‹œê°„ ì•Œë¦¼ì´ í•„ìš”í•œ ê²½ìš° ì•„ë˜ ì£¼ì„ í•´ì œ
            # self.alert_producer.send_anomaly_alert(
            #     machine_id=machine_id,
            #     alert_data=outbox_event.payload
            # )

        except Exception as e:
            logger.error(f"ì´ìƒ íƒì§€ ì´ë²¤íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _signal_handler(self, signum, frame):
        """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ (Ctrl+C, SIGTERM)"""
        logger.info(f"ì‹œê·¸ë„ ìˆ˜ì‹ : {signum}, Consumer ì¢…ë£Œ ì¤‘...")
        self.running = False

    def stop(self) -> None:
        """Consumer ì•ˆì „ ì¢…ë£Œ"""
        logger.info("SensorDataConsumer ì¢…ë£Œ ì¤‘...")
        self.running = False

        try:
            # Consumer ì¢…ë£Œ
            self.consumer.close()
            logger.info("Kafka Consumer ì¢…ë£Œ ì™„ë£Œ")

            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            self.alert_producer.close()
            self.cache.close()
            self.repository.close()

        except Exception as e:
            logger.error(f"Consumer ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")

    def get_metrics(self) -> dict:
        """
        Consumer ë©”íŠ¸ë¦­ ì¡°íšŒ

        Returns:
            ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
        """
        try:
            metrics = self.consumer.metrics()
            return {
                'records_consumed_rate': metrics.get('records-consumed-rate', {}).get('metric-value'),
                'fetch_latency_avg': metrics.get('fetch-latency-avg', {}).get('metric-value'),
                'commit_latency_avg': metrics.get('commit-latency-avg', {}).get('metric-value')
            }
        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}


# Consumer ì‹¤í–‰ í•¨ìˆ˜
def run_consumer():
    """Consumerë¥¼ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    consumer = SensorDataConsumer()
    consumer.start()


if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # Consumer ì‹¤í–‰
    run_consumer()
