# ğŸ­ Predictive Maintenance - Data Analysis & Model Selection Report

## ğŸ“‹ Executive Summary

**ë¶„ì„ ì¼ì**: 2025-11-18
**ë°ì´í„°ì…‹**: predictive_maintenance.csv
**ë¶„ì„ ëª©ì **: ì„¤ë¹„ ê³ ì¥ ì˜ˆì¸¡ì„ ìœ„í•œ ìµœì  ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„ ì •
**ë¶„ì„ ë„êµ¬**: Python, Scikit-learn, XGBoost, LightGBM, CatBoost

---

## 1. ë°ì´í„° ê°œìš”

### 1.1 ë°ì´í„°ì…‹ ì •ë³´
- **ì´ ë ˆì½”ë“œ ìˆ˜**: 10,000ê°œ
- **íŠ¹ì„± ìˆ˜**: 10ê°œ (ì›ë³¸) â†’ 16ê°œ (Feature Engineering í›„)
- **íƒ€ê²Ÿ ë³€ìˆ˜**: Binary Classification (0: No Failure, 1: Failure)
- **ê²°ì¸¡ì¹˜**: ì—†ìŒ
- **ì¤‘ë³µ ë°ì´í„°**: ì—†ìŒ

### 1.2 ë°ì´í„° êµ¬ì¡°

| ì»¬ëŸ¼ëª… | ë°ì´í„° íƒ€ì… | ì„¤ëª… |
|--------|------------|------|
| UDI | Integer | Unique Device Identifier |
| Product ID | String | ì œí’ˆ ê³ ìœ  ID |
| Type | Categorical | ì œí’ˆ íƒ€ì… (L/M/H) |
| Air temperature [K] | Float | ê³µê¸° ì˜¨ë„ (ì¼ˆë¹ˆ) |
| Process temperature [K] | Float | ê³µì • ì˜¨ë„ (ì¼ˆë¹ˆ) |
| Rotational speed [rpm] | Integer | íšŒì „ ì†ë„ (RPM) |
| Torque [Nm] | Float | í† í¬ (ë‰´í„´ë¯¸í„°) |
| Tool wear [min] | Integer | ê³µêµ¬ ë§ˆëª¨ ì‹œê°„ (ë¶„) |
| Target | Binary | ê³ ì¥ ì—¬ë¶€ (0/1) |
| Failure Type | Categorical | ê³ ì¥ ìœ í˜• |

---

## 2. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)

### 2.1 íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬

**Class Distribution**:
- No Failure (0): [ì‹¤í–‰ í›„ ê¸°ë¡]
- Failure (1): [ì‹¤í–‰ í›„ ê¸°ë¡]
- **Imbalance Ratio**: [ì‹¤í–‰ í›„ ê¸°ë¡]:1

**ë¶„ì„ ê²°ê³¼**: [ì‹¤í–‰ í›„ ê¸°ë¡]

### 2.2 ê³ ì¥ ìœ í˜• ë¶„ì„

**Failure Type Distribution**:
[ì‹¤í–‰ í›„ ê¸°ë¡]

**ì£¼ìš” ë°œê²¬ì‚¬í•­**:
- [ì‹¤í–‰ í›„ ê¸°ë¡]

### 2.3 ì œí’ˆ íƒ€ì…ë³„ ë¶„ì„

**Product Type vs Failure Rate**:
[ì‹¤í–‰ í›„ ê¸°ë¡]

**ì¸ì‚¬ì´íŠ¸**:
- [ì‹¤í–‰ í›„ ê¸°ë¡]

### 2.4 ìˆ˜ì¹˜í˜• íŠ¹ì„± ë¶„ì„

**ìƒê´€ê´€ê³„ ë¶„ì„**:
- Targetê³¼ ê°€ì¥ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” íŠ¹ì„±: [ì‹¤í–‰ í›„ ê¸°ë¡]
- íŠ¹ì„± ê°„ ë‹¤ì¤‘ê³µì„ ì„±: [ì‹¤í–‰ í›„ ê¸°ë¡]

**ì´ìƒì¹˜ ë¶„ì„**:
- [ì‹¤í–‰ í›„ ê¸°ë¡]

---

## 3. Feature Engineering

### 3.1 ìƒì„±ëœ íŠ¹ì„±

ë‹¤ìŒ 6ê°œì˜ íŒŒìƒ íŠ¹ì„±ì„ ìƒì„±í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì„ ë„ëª¨:

1. **Temp_diff** (ì˜¨ë„ ì°¨ì´)
   - `Process temperature - Air temperature`
   - **ëª©ì **: ê³µì • ì˜¨ë„ì™€ ê³µê¸° ì˜¨ë„ ê°„ ì°¨ì´ê°€ ê³ ì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„

2. **Power** (ë™ë ¥)
   - `Torque Ã— Rotational speed / 1000`
   - **ëª©ì **: ê¸°ê³„ì˜ ì‹¤ì œ ë™ë ¥ ì†Œë¹„ëŸ‰ ê³„ì‚°

3. **Tool_wear_rate** (ê³µêµ¬ ë§ˆëª¨ìœ¨)
   - `Tool wear / (Rotational speed + 1)`
   - **ëª©ì **: íšŒì „ ì†ë„ ëŒ€ë¹„ ê³µêµ¬ ë§ˆëª¨ ë¹„ìœ¨

4. **Torque_speed_ratio** (í† í¬-ì†ë„ ë¹„ìœ¨)
   - `Torque / (Rotational speed + 1)`
   - **ëª©ì **: í† í¬ì™€ ì†ë„ ê°„ ê´€ê³„ ë¶„ì„

5. **Temp_toolwear** (ì˜¨ë„-ë§ˆëª¨ ìƒí˜¸ì‘ìš©)
   - `Process temperature Ã— Tool wear`
   - **ëª©ì **: ì˜¨ë„ì™€ ê³µêµ¬ ë§ˆëª¨ì˜ ë³µí•© íš¨ê³¼

6. **Type_encoded** (ì œí’ˆ íƒ€ì… ì¸ì½”ë”©)
   - Label Encoding of Product Type (L/M/H)
   - **ëª©ì **: ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ìˆ˜ì¹˜í™”

### 3.2 ì „ì²˜ë¦¬ ê³¼ì •

1. **Feature Scaling**: StandardScaler ì ìš©
   - ëª¨ë“  ìˆ˜ì¹˜í˜• íŠ¹ì„±ì„ í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ì •ê·œí™”

2. **Class Imbalance ì²˜ë¦¬**: SMOTE (Synthetic Minority Over-sampling Technique)
   - ì†Œìˆ˜ í´ë˜ìŠ¤(Failure) ìƒ˜í”Œì„ í•©ì„±í•˜ì—¬ ê· í˜• ì¡°ì •
   - ì ìš© ì „: [ì‹¤í–‰ í›„ ê¸°ë¡]
   - ì ìš© í›„: [ì‹¤í–‰ í›„ ê¸°ë¡]

3. **Train-Test Split**: 80% / 20% (Stratified)
   - í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ë°ì´í„° ë¶„í• 

---

## 4. ëª¨ë¸ í•™ìŠµ ë° ë¹„êµ

### 4.1 í•™ìŠµëœ ëª¨ë¸ ëª©ë¡

ì´ 9ê°œì˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ë¹„êµ:

1. **Logistic Regression**
2. **Decision Tree**
3. **Random Forest**
4. **Gradient Boosting**
5. **XGBoost**
6. **LightGBM**
7. **CatBoost**
8. **Support Vector Machine (SVM)**
9. **K-Nearest Neighbors (KNN)**

### 4.2 í‰ê°€ ì§€í‘œ

ê° ëª¨ë¸ì€ ë‹¤ìŒ ì§€í‘œë¡œ í‰ê°€:

- **Accuracy**: ì „ì²´ ì •í™•ë„
- **Precision**: ì •ë°€ë„ (Failure ì˜ˆì¸¡ì˜ ì •í™•ì„±)
- **Recall**: ì¬í˜„ìœ¨ (ì‹¤ì œ Failure íƒì§€ìœ¨)
- **F1-Score**: Precisionê³¼ Recallì˜ ì¡°í™” í‰ê· 
- **ROC-AUC**: ROC ê³¡ì„  ì•„ë˜ ë©´ì 
- **Overfitting**: Train-Test Accuracy ì°¨ì´

### 4.3 ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼

[Jupyter Notebook ì‹¤í–‰ í›„ ì‘ì„±]

| Model | Test Accuracy | Precision | Recall | F1-Score | ROC-AUC | Overfitting |
|-------|---------------|-----------|--------|----------|---------|-------------|
| [ëª¨ë¸ëª…] | [ê°’] | [ê°’] | [ê°’] | [ê°’] | [ê°’] | [ê°’] |
| ... | ... | ... | ... | ... | ... | ... |

**ì„±ëŠ¥ ìˆœìœ„ (F1-Score ê¸°ì¤€)**:
1. [ì‹¤í–‰ í›„ ê¸°ë¡]
2. [ì‹¤í–‰ í›„ ê¸°ë¡]
3. [ì‹¤í–‰ í›„ ê¸°ë¡]

---

## 5. ìµœì¢… ëª¨ë¸ ì„ ì •

### 5.1 ì„ ì • ê¸°ì¤€

ìµœì  ëª¨ë¸ ì„ ì •ì„ ìœ„í•´ ë‹¤ìŒ ê¸°ì¤€ì„ ì ìš©:

1. **ë†’ì€ F1-Score** (ìš°ì„ ìˆœìœ„ 1)
   - Imbalanced Datasetì—ì„œ Precisionê³¼ Recallì˜ ê· í˜•ì´ ì¤‘ìš”

2. **ë‚®ì€ Overfitting** (Train-Test Accuracy ì°¨ì´ < 0.1)
   - ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œì˜ ì¼ë°˜í™” ì„±ëŠ¥ ë³´ì¥

3. **ë†’ì€ Recall**
   - ì‹¤ì œ ê³ ì¥ì„ ë†“ì¹˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¤‘ìš” (False Negative ìµœì†Œí™”)

4. **ë†’ì€ ROC-AUC**
   - ì „ë°˜ì ì¸ ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€

### 5.2 ìµœì¢… ì„ ì • ëª¨ë¸

**ğŸ† ì„ ì • ëª¨ë¸**: [ì‹¤í–‰ í›„ ê¸°ë¡]

**ì„±ëŠ¥ ì§€í‘œ**:
- Test Accuracy: [ì‹¤í–‰ í›„ ê¸°ë¡]
- Precision: [ì‹¤í–‰ í›„ ê¸°ë¡]
- Recall: [ì‹¤í–‰ í›„ ê¸°ë¡]
- F1-Score: [ì‹¤í–‰ í›„ ê¸°ë¡]
- ROC-AUC: [ì‹¤í–‰ í›„ ê¸°ë¡]
- Overfitting: [ì‹¤í–‰ í›„ ê¸°ë¡]

**ì„ ì • ì´ìœ **:
[ì‹¤í–‰ í›„ ê¸°ë¡]

### 5.3 Confusion Matrix

[ì‹¤í–‰ í›„ ê¸°ë¡]

```
                 Predicted
                 No Failure  Failure
Actual No Failure    [TN]      [FP]
       Failure       [FN]      [TP]
```

**í•´ì„**:
- True Negative (TN): [ì‹¤í–‰ í›„ ê¸°ë¡]
- False Positive (FP): [ì‹¤í–‰ í›„ ê¸°ë¡]
- False Negative (FN): [ì‹¤í–‰ í›„ ê¸°ë¡]
- True Positive (TP): [ì‹¤í–‰ í›„ ê¸°ë¡]

### 5.4 Feature Importance (Tree-based Modelì¸ ê²½ìš°)

[ì‹¤í–‰ í›„ ê¸°ë¡]

**Top 5 Important Features**:
1. [ì‹¤í–‰ í›„ ê¸°ë¡]
2. [ì‹¤í–‰ í›„ ê¸°ë¡]
3. [ì‹¤í–‰ í›„ ê¸°ë¡]
4. [ì‹¤í–‰ í›„ ê¸°ë¡]
5. [ì‹¤í–‰ í›„ ê¸°ë¡]

---

## 6. ëª¨ë¸ í•´ì„ ë° ì¸ì‚¬ì´íŠ¸

### 6.1 ì£¼ìš” ë°œê²¬ì‚¬í•­

1. **ê³ ì¥ ì˜ˆì¸¡ì— ê°€ì¥ ì¤‘ìš”í•œ ìš”ì¸**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

2. **ì œí’ˆ íƒ€ì…ë³„ ê³ ì¥ íŒ¨í„´**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

3. **ì˜¨ë„ì™€ ê³ ì¥ì˜ ê´€ê³„**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

4. **ê³µêµ¬ ë§ˆëª¨ì˜ ì˜í–¥**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

### 6.2 ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸

1. **ì˜ˆë°© ì •ë¹„ ì „ëµ**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

2. **ëª¨ë‹ˆí„°ë§ ìš°ì„ ìˆœìœ„**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

3. **ì˜ˆìƒ íš¨ê³¼**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

---

## 7. ëª¨ë¸ ë°°í¬ ë° í™œìš© ë°©ì•ˆ

### 7.1 ëª¨ë¸ ì €ì¥

**ì €ì¥ëœ íŒŒì¼**:
- `models/final_model_[ëª¨ë¸ëª…].pkl`: í•™ìŠµëœ ëª¨ë¸
- `models/scaler.pkl`: Feature Scaler
- `models/label_encoder_type.pkl`: Product Type Encoder
- `models/feature_names.pkl`: íŠ¹ì„± ì´ë¦„ ëª©ë¡
- `models/model_comparison_results.csv`: ì „ì²´ ëª¨ë¸ ë¹„êµ ê²°ê³¼

### 7.2 ëª¨ë¸ ì‚¬ìš© ì˜ˆì œ

```python
import joblib
import pandas as pd

# ëª¨ë¸ ë° ì „ì²˜ë¦¬ ê°ì²´ ë¡œë“œ
model = joblib.load('models/final_model_[ëª¨ë¸ëª…].pkl')
scaler = joblib.load('models/scaler.pkl')
feature_names = joblib.load('models/feature_names.pkl')

# ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡
def predict_failure(input_data):
    # Feature Engineering ì ìš©
    # ... (ë™ì¼í•œ Feature Engineering ë¡œì§)

    # Scaling
    input_scaled = scaler.transform(input_data[feature_names])

    # ì˜ˆì¸¡
    prediction = model.predict(input_scaled)
    probability = model.predict_proba(input_scaled)

    return prediction, probability
```

### 7.3 FastAPI ì„œë²„ í†µí•© ê³„íš

**API Endpoint ì„¤ê³„**:
```python
POST /api/predict
{
  "air_temperature": 298.1,
  "process_temperature": 308.6,
  "rotational_speed": 1551,
  "torque": 42.8,
  "tool_wear": 0,
  "product_type": "M"
}

Response:
{
  "prediction": "No Failure",
  "failure_probability": 0.05,
  "confidence": 0.95,
  "recommendations": ["Monitor tool wear", ...]
}
```

### 7.4 ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì—°ë™

1. **Kafka Integration**:
   - ì„¼ì„œ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì„ Kafkaë¡œ ìˆ˜ì§‘
   - ì‹¤ì‹œê°„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ anomaly-alerts í† í”½ìœ¼ë¡œ ë°œí–‰

2. **Database Logging**:
   - ì˜ˆì¸¡ ê²°ê³¼ë¥¼ PostgreSQLì— ì €ì¥
   - ì‹œê³„ì—´ ë¶„ì„ ë° ëŒ€ì‹œë³´ë“œ êµ¬ì„±

---

## 8. ì œí•œì‚¬í•­ ë° ê°œì„  ë°©í–¥

### 8.1 í˜„ì¬ ì œí•œì‚¬í•­

1. **ë°ì´í„° ì œí•œ**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

2. **ëª¨ë¸ ì œí•œ**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

3. **ë°°í¬ ì œí•œ**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

### 8.2 í–¥í›„ ê°œì„  ë°©í–¥

1. **ë°ì´í„° ìˆ˜ì§‘**:
   - ë” ë§ì€ ì‹¤ì œ ê³ ì¥ ë°ì´í„° í™•ë³´
   - ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ ì—°ì† ë°ì´í„° ìˆ˜ì§‘

2. **ëª¨ë¸ ê³ ë„í™”**:
   - Ensemble ê¸°ë²• ì ìš© (Stacking, Blending)
   - Deep Learning ëª¨ë¸ ì‹¤í—˜ (LSTM, Transformer)
   - AutoML ë„êµ¬ í™œìš© (Hyperparameter Tuning)

3. **ì‹¤ì‹œê°„ í•™ìŠµ**:
   - Online Learning êµ¬í˜„
   - Concept Drift ê°ì§€ ë° ëŒ€ì‘

4. **ì„¤ëª… ê°€ëŠ¥ì„±**:
   - SHAP, LIME ë“±ì„ í™œìš©í•œ ëª¨ë¸ í•´ì„
   - ê³ ì¥ ì›ì¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìë™ ìƒì„±

---

## 9. ê²°ë¡ 

### 9.1 í”„ë¡œì íŠ¸ ìš”ì•½

ë³¸ ë¶„ì„ì„ í†µí•´ ì„¤ë¹„ ì„¼ì„œ ë°ì´í„°ë¥¼ í™œìš©í•œ ê³ ì¥ ì˜ˆì¸¡ ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ê°œë°œ:

- âœ… **9ê°œ ëª¨ë¸ ë¹„êµ ë¶„ì„** ì™„ë£Œ
- âœ… **ìµœì  ëª¨ë¸ ì„ ì •** ë° ê²€ì¦
- âœ… **Feature Engineering**ì„ í†µí•œ ì„±ëŠ¥ í–¥ìƒ
- âœ… **Class Imbalance ë¬¸ì œ** í•´ê²°
- âœ… **Overfitting ìµœì†Œí™”**

### 9.2 ìµœì¢… ê¶Œê³ ì‚¬í•­

1. **ì¦‰ì‹œ ì ìš© ê°€ëŠ¥**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

2. **ë‹¨ê¸° ê°œì„  (1-3ê°œì›”)**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

3. **ì¤‘ì¥ê¸° ê°œì„  (3-6ê°œì›”)**:
   - [ì‹¤í–‰ í›„ ê¸°ë¡]

---

## 10. ë¶€ë¡

### 10.1 ì°¸ê³  ìë£Œ

- Kaggle: Failure Prediction with XGBoost (https://www.kaggle.com/code/huda1102/failure-pred-xgboost)
- Scikit-learn Documentation
- XGBoost Documentation
- LightGBM Documentation
- CatBoost Documentation

### 10.2 ì‹¤í–‰ í™˜ê²½

- **Python Version**: 3.8+
- **ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬**:
  - pandas >= 2.0.0
  - scikit-learn >= 1.3.0
  - xgboost >= 2.0.0
  - lightgbm >= 4.0.0
  - catboost >= 1.2.0
  - imbalanced-learn >= 0.11.0

### 10.3 ì¬í˜„ ë°©ë²•

1. í™˜ê²½ ì„¤ì •:
   ```bash
   pip install -r requirements.txt
   ```

2. Jupyter Notebook ì‹¤í–‰:
   ```bash
   jupyter notebook predictive_maintenance_analysis.ipynb
   ```

3. ëª¨ë“  ì…€ ìˆœì°¨ ì‹¤í–‰

---

**ë³´ê³ ì„œ ì‘ì„±ì¼**: 2025-11-18
**ì‘ì„±ì**: ML Engineer
**ë²„ì „**: 1.0 (Draft)

